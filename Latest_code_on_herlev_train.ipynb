{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arya703/cervical_cancer_detection/blob/main/Latest_code_on_herlev_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I5zN0TTNS0S_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESQVbw_ITAoQ",
        "outputId": "0103fef7-7eff-4f1b-f636-390339803667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LDkW80EXTUOg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Activation, Multiply, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "39d3SFlwTX6n"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def load_data(base_path):\n",
        "    images, labels = [], []\n",
        "    for category in os.listdir(base_path):\n",
        "        folder_path = os.path.join(base_path, category)\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            image = cv2.imread(os.path.join(folder_path, file_name))\n",
        "            image = cv2.resize(image, (128, 128))\n",
        "            images.append(image)\n",
        "            labels.append(category)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Herlev dataset (training)\n",
        "image_path = '/content/drive/MyDrive/Herlev Dataset/train'\n",
        "mask_path='/content/drive/My Drive/Herlev Dataset/train/'\n",
        "X_train, y_train = load_data(image_path)\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "# Shuffle data\n",
        "X_train, y_train_encoded = shuffle(X_train, y_train_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset path\n",
        "test_image_path = '/content/drive/MyDrive/Herlev Dataset/test'\n",
        "\n",
        "# Load and preprocess test dataset\n",
        "X_test, y_test = load_data(test_image_path)\n",
        "\n",
        "# Encode test labels\n",
        "y_test_encoded = encoder.transform(y_test)  # Ensure to use the same encoder as training\n",
        "\n",
        "# Normalize images (if done for training data)\n",
        "X_test = X_test / 255.0\n"
      ],
      "metadata": {
        "id": "VFpghWL68xir"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gOfBP3XUm1s",
        "outputId": "d572a564-6104-4bf2-d3ff-001657d30647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['moderate_dysplastic', 'carcinoma_in_situ', 'severe_dysplastic', 'light_dysplastic', 'normal_intermediate', 'normal_columnar', 'normal_superficiel']\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir(image_path)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1XjE6PQUrHn",
        "outputId": "8a50b931-6c01-4420-f7b9-8ddaa9e87eb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V0Q6M2JHUuc-"
      },
      "outputs": [],
      "source": [
        "def load_img(folder):\n",
        "    images = []\n",
        "    for root, _, filenames in os.walk(folder):\n",
        "        for filename in filenames:\n",
        "            img_path = os.path.join(root, filename)\n",
        "            if os.path.isfile(img_path):\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    images.append(img)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "beUk_lmCUzPb"
      },
      "outputs": [],
      "source": [
        "def load_mask(folder):\n",
        "    masks = []\n",
        "    for root, _, filenames in os.walk(folder):\n",
        "        for filename in filenames:\n",
        "            mask_path = os.path.join(root, filename)\n",
        "            if os.path.isfile(mask_path):\n",
        "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
        "                if mask is not None:\n",
        "                    masks.append(mask)\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YrZc1bToU4su"
      },
      "outputs": [],
      "source": [
        "images = load_img(image_path)\n",
        "masks=load_mask(mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "PoyVFwSUVkCz",
        "outputId": "e5abf54d-d5bc-4314-b716-cda2be2e3d71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=136x68>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "if len(images) > 0:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    cv2_imshow(images[0])\n",
        "else:\n",
        "    print(\"No images found in the directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FARV_GCgVzzM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Activation, Multiply, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "flBwcQ4xV4iK"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define data augmentation techniques\n",
        "data_gen_args = ImageDataGenerator(rotation_range=30,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    shear_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest', # Add a comma here\n",
        "                    brightness_range=[0.8, 1.2], # Align with other arguments\n",
        "                    preprocessing_function=lambda x: cv2.GaussianBlur(x, (3, 3), 0)) # Align with other arguments\n",
        "\n",
        "\n",
        "train_gen = data_gen_args.flow(X_train, y_train_encoded, batch_size=16) # Change datagen to data_gen_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPyREsV9V8f-",
        "outputId": "3d9b8506-2755-4615-ff3b-0eb663e9bbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 643 images belonging to 7 classes.\n",
            "Found 643 images belonging to 7 classes.\n",
            "Image shape: (32, 128, 128, 3)\n",
            "Mask shape: (32, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "# Initialize ImageDataGenerators for training images and masks\n",
        "# Instead of get_config, directly pass the arguments\n",
        "image_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=data_gen_args.rotation_range,\n",
        "                                   width_shift_range=data_gen_args.width_shift_range,\n",
        "                                   height_shift_range=data_gen_args.height_shift_range,\n",
        "                                   shear_range=data_gen_args.shear_range,\n",
        "                                   zoom_range=data_gen_args.zoom_range,\n",
        "                                   horizontal_flip=data_gen_args.horizontal_flip,\n",
        "                                   fill_mode=data_gen_args.fill_mode,\n",
        "                                   brightness_range=data_gen_args.brightness_range,\n",
        "                                   preprocessing_function=data_gen_args.preprocessing_function)\n",
        "mask_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "# Load training images and masks\n",
        "image_generator_train = image_datagen.flow_from_directory(\n",
        "    image_path,  # Path to training image directory\n",
        "    target_size=(128, 128),  # Resize images to match model input size\n",
        "    batch_size=32,\n",
        "    class_mode=None,  # No labels for segmentation\n",
        "    seed=42\n",
        ")\n",
        "mask_generator_train = mask_datagen.flow_from_directory(\n",
        "    mask_path,  # Path to masks\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',  # Ensure masks are single-channel\n",
        "    class_mode=None,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Check the shape of the output from the generators\n",
        "# Should print the shape of image and mask batches\n",
        "images, masks = next(zip(image_generator_train, mask_generator_train))\n",
        "print(\"Image shape:\", images.shape)  # (batch_size, 128, 128, 3)\n",
        "print(\"Mask shape:\", masks.shape)  # (batch_size, 128, 128, 1)\n",
        "\n",
        "# Combine image and mask generators for segmentation\n",
        "train_generator = zip(image_generator_train, mask_generator_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YDpVmT2WC0C",
        "outputId": "0a80b027-7bb3-4ac0-c0c2-ab701c801ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images: (32, 128, 128, 3)\n",
            "Shape of masks: (32, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "# Print the first batch of images and masks to verify compatibility\n",
        "images, masks = next(train_generator)\n",
        "print(\"Shape of images:\", images.shape)  # Should be (batch_size, 128, 128, 3)\n",
        "print(\"Shape of masks:\", masks.shape)  # Should be (batch_size, 128, 128, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZCP1sz6WMF3",
        "outputId": "0c641bb6-ee33-42a5-fa1c-f04c0ba256d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step\n"
          ]
        }
      ],
      "source": [
        "# Initialize ResNet-50 model for feature extraction\n",
        "from keras.applications import ResNet50\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "# Change input_shape to (128, 128, 3)\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
        "\n",
        "# Adding custom layers for feature extraction\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)  # Additional fully connected layer\n",
        "\n",
        "# Final model for feature extraction\n",
        "feature_extraction_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Freeze ResNet-50 layers for transfer learning\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Extract features\n",
        "# Changed line: Using 'feature_extraction_model' instead of 'resnet_model'\n",
        "X_train_features = feature_extraction_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9g70tQGhWQ_i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DpRsyjVUWj-t"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, Activation, Multiply, Add\n",
        "\n",
        "def attention_block(x, gating, inter_channels):\n",
        "    # 1x1 Conv for the input tensor\n",
        "    theta_x = Conv2D(inter_channels, (1, 1), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    # 1x1 Conv for the gating tensor\n",
        "    phi_g = Conv2D(inter_channels, (1, 1), strides=(1, 1), padding='same')(gating)\n",
        "\n",
        "    # Sum the two feature maps\n",
        "    concat_xg = Add()([theta_x, phi_g])\n",
        "    concat_xg = Activation('relu')(concat_xg)\n",
        "\n",
        "    # 1x1 Conv to reduce dimensionality\n",
        "    psi = Conv2D(1, (1, 1), strides=(1, 1), padding='same')(concat_xg)\n",
        "    psi = Activation('sigmoid')(psi)\n",
        "\n",
        "    # Multiply attention map with the original input\n",
        "    att_out = Multiply()([x, psi])\n",
        "    return att_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qnfHD7gFWrSG"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, UpSampling2D, Input, BatchNormalization, Activation, Reshape, MaxPooling2D\n",
        "# Ensure 'concatenate' is imported correctly\n",
        "from keras.layers import concatenate  # or 'from tensorflow.keras.layers import concatenate'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def att_unet(input_size=(128, 128, 3), num_classes=7): # Assuming 7 classes in Herlev dataset\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
        "    att4 = attention_block(conv2, up4, 128)\n",
        "    # Pass the list of tensors to concatenate directly, with axis as a keyword argument\n",
        "    concat4 = concatenate([att4, up4], axis=3)\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat4)\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    att5 = attention_block(conv1, up5, 64)\n",
        "    # Pass the list of tensors to concatenate directly, with axis as a keyword argument\n",
        "    concat5 = concatenate([att5, up5], axis=3)\n",
        "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat5)\n",
        "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Output layer - Multi-class\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(conv5)  # 'softmax' for multi-class\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PnmpIJyaWwaM"
      },
      "outputs": [],
      "source": [
        "# Now, in your training code:\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "# Change the filepath to end with '.keras' or set save_weights_only=True\n",
        "model_checkpoint = ModelCheckpoint('best_model_herlev.keras', save_best_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "w8_EqmYPW0cr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def combine_generators(image_generator, mask_generator):\n",
        "    \"\"\"Combines image and mask generators into a single generator,\n",
        "       and one-hot encodes the masks.\"\"\"\n",
        "    # Perform one-hot encoding outside the loop\n",
        "    num_classes = 7  # Assuming you have 7 classes\n",
        "    while True:  # Add this loop for continuous generation of batches\n",
        "        for image_batch, mask_batch in zip(image_generator, mask_generator):\n",
        "            mask_batch_encoded = tf.keras.utils.to_categorical(mask_batch, num_classes=num_classes)\n",
        "            yield image_batch, mask_batch_encoded\n",
        "    # Explicitly return None when the loop is broken to handle cases where data runs out.\n",
        "    # This should not be reached if the loop is correctly structured but it can improve troubleshooting.\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eLUwEMkHW4w2"
      },
      "outputs": [],
      "source": [
        "train_generator_combined = combine_generators(image_generator_train, mask_generator_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BJLIhw_UW8zi"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = att_unet(input_size=(128, 128, 3))\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss for multi class segmentation\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiDRnGysXAIc",
        "outputId": "d9ee9c3d-dacf-4d6e-b341-033199a04e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 35s/step - accuracy: 0.8306 - loss: 0.7415 - learning_rate: 0.0010\n",
            "Epoch 2/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
            "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 35s/step - accuracy: 0.9991 - loss: 0.0304 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 35s/step - accuracy: 0.9990 - loss: 0.0181 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 35s/step - accuracy: 0.9989 - loss: 0.0221 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 35s/step - accuracy: 0.9996 - loss: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 35s/step - accuracy: 0.9987 - loss: 0.0148 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 35s/step - accuracy: 0.9985 - loss: 0.0192 - learning_rate: 0.0010\n",
            "Epoch 8/25\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_generator_combined , epochs=25, steps_per_epoch=len(image_generator_train), callbacks=[reduce_lr, early_stopping, model_checkpoint]) #"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMvDOgJVc1FIxfuezioeMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}